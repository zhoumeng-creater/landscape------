"""
é…ç½®æ–‡ä»¶ - åŒ…å«æ‰€æœ‰è®­ç»ƒå’Œæ¨¡å‹ç›¸å…³çš„é…ç½®å‚æ•°
"""
import torch
import os

class Config:
    """é…ç½®ç±» - åŒ…å«æ‰€æœ‰è¶…å‚æ•°å’Œè·¯å¾„é…ç½®"""
    
    # ============================== åŸºç¡€é…ç½® ==============================
    # éšæœºç§å­
    SEED = 42
    
    # è®¾å¤‡é…ç½®
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # æ•°æ®è·¯å¾„
    DATA_PATH = '/kaggle/input/yuanlin-dataset/yuanlin_dataset'
    
    # ä¿å­˜è·¯å¾„
    CHECKPOINT_DIR = './checkpoints'
    PRETRAIN_MODEL_PATH = 'optimized_ijepa_best.pth'  # ä¿ç•™å…¼å®¹æ€§
    FINETUNE_MODEL_PATH = 'optimized_best_classifier.pth'
    PRETRAINED_MODEL_PATH = 'pretrained_best_model.pth'  # æ–°å¢
    
    # ============================== æ¨¡å‹é€‰æ‹© ==============================
    # æ¨¡å‹ç±»å‹é€‰æ‹©
    MODEL_TYPE = 'hybrid_ijepa'  # å¯é€‰: 'ijepa', 'hybrid_ijepa', 'pretrained', 'ensemble', 'lightweight'
    
    # é¢„è®­ç»ƒæ¨¡å‹é…ç½®
    PRETRAINED_MODEL_NAME = 'vit_base_patch16_224.dino'  # æ¨èé€‰é¡¹:
    # - 'vit_base_patch16_224.dino' (æœ€ä½³ç‰¹å¾è´¨é‡)
    # - 'vit_base_patch16_clip_224.openai' (è¯­ä¹‰ç†è§£å¼º)
    # - 'convnext_base.fb_in22k_ft_in1k' (ç»†ç²’åº¦åˆ†ç±»å¥½)
    # - 'swin_base_patch4_window7_224' (å±‚æ¬¡åŒ–ç‰¹å¾)
    # - 'efficientnet_b3' (è½»é‡çº§ï¼Œé€‚åˆP100)
    
    # å†»ç»“å±‚æ•°ï¼ˆé¢„è®­ç»ƒæ¨¡å‹ï¼‰
    FREEZE_LAYERS = 6  # ViTæœ‰12å±‚ï¼Œå†»ç»“å‰6å±‚
    
    # åˆ†ç±»å™¨é…ç½®
    CLASSIFIER_DROPOUT = 0.5

    # ============================== æ•°æ®é…ç½® ==============================
    # å›¾åƒé…ç½®
    IMG_SIZE = 224
    PATCH_SIZE = 16
    IN_CHANNELS = 3
    
    # æ•°æ®é›†åˆ†å‰²
    TEST_SIZE = 0.2
    VAL_SIZE = 0.1
    
    # æ•°æ®åŠ è½½
    BATCH_SIZE_PRETRAIN = 20  # ä¿ç•™åŸè®¾ç½®
    BATCH_SIZE_FINETUNE = 16  # å‡å°ä»¥é€‚åº”æ›´å¤§çš„æ¨¡å‹
    BATCH_SIZE_EVAL = 32
    NUM_WORKERS = 2
    
    # ============================== åŸI-JEPAæ¨¡å‹é…ç½®ï¼ˆä¿ç•™å…¼å®¹ï¼‰ ==============================
    # Transformeré…ç½®
    EMBED_DIM = 768
    DEPTH = 12
    N_HEADS = 12
    MLP_RATIO = 4
    
    # Predictoré…ç½®
    PREDICTOR_DEPTH = 6
    
    # ============================== è®­ç»ƒé…ç½® ==============================
    # è®­ç»ƒæ¨¡å¼
    USE_PRETRAINED_MODEL = True  # æ˜¯å¦ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
    SKIP_PRETRAIN = False  # è·³è¿‡I-JEPAé¢„è®­ç»ƒé˜¶æ®µ
    
    # é¢„è®­ç»ƒé…ç½®ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
    PRETRAIN_EPOCHS = 30
    PRETRAIN_LR = 3e-5
    PRETRAIN_WEIGHT_DECAY = 0.05
    PRETRAIN_BETAS = (0.9, 0.95)  # AdamWçš„betaå‚æ•° - æ·»åŠ è¿™ä¸€è¡Œï¼
    
    # I-JEPAç‰¹å®šé…ç½® - ä¹Ÿéœ€è¦æ·»åŠ è¿™äº›
    EMA_MOMENTUM = 0.996  # ç›®æ ‡ç¼–ç å™¨çš„EMAåŠ¨é‡
    WARMUP_EPOCHS = 5     # å­¦ä¹ ç‡é¢„çƒ­è½®æ•°
    LOG_INTERVAL = 50     # æ‰“å°æ—¥å¿—çš„é—´éš”
    PATIENCE_PRETRAIN = 10  # é¢„è®­ç»ƒæ—©åœè€å¿ƒå€¼
    
    # å¾®è°ƒé…ç½®
    FINETUNE_EPOCHS = 30  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶å¯ä»¥å‡å°‘
    FINETUNE_LR = 5e-5  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶è¦ç”¨æ›´å°çš„å­¦ä¹ ç‡
    FINETUNE_WEIGHT_DECAY = 0.01
    FINETUNE_STAGE2_EPOCH = 10  # å¼€å§‹è§£å†»æ›´å¤šå±‚
    FINETUNE_LR_RATIO = 10
    
    # ä¼˜åŒ–å™¨é…ç½®
    OPTIMIZER_TYPE = 'adamw'  # å¯é€‰: 'adamw', 'lamb', 'lion'
    USE_SAM = False  # ç¦ç”¨SAMä¼˜åŒ–å™¨
    SAM_RHO = 0.05
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    USE_AMP = True  # ä½¿ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦è®­ç»ƒ
    
    # æ¢¯åº¦ç´¯ç§¯
    GRADIENT_ACCUMULATION_STEPS = 2  # æ¨¡æ‹Ÿæ›´å¤§çš„batch size
    
    # æŸå¤±å‡½æ•°é…ç½®
    LABEL_SMOOTHING = 0.1
    USE_AUXILIARY_LOSS = True  # ä½¿ç”¨è¾…åŠ©æŸå¤±
    AUX_LOSS_WEIGHT = 0.3
    
    # æ­£åˆ™åŒ–é…ç½®
    DROP_PATH_RATE = 0.1
    LAYER_SCALE_INIT = 1e-4
    GRADIENT_CLIP = 1.0
    
    # ============================== è¯„ä¼°é…ç½® ==============================
    # æ—©åœé…ç½®
    PATIENCE_PRETRAIN = 20
    PATIENCE_FINETUNE = 10  # ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ”¶æ•›æ›´å¿«
    
    # æµ‹è¯•æ—¶å¢å¼º
    USE_TTA = True  # Test Time Augmentation
    TTA_TIMES = 5  # TTAæ¬¡æ•°
    
    # æ—¥å¿—é…ç½®
    LOG_INTERVAL = 100
    SAVE_BEST_ONLY = True

    # ============================== æ•°æ®å¢å¼ºé…ç½® ==============================
    # å¢å¼ºçº§åˆ«
    AUGMENTATION_LEVEL = 'strong'  # å¯é€‰: 'basic', 'medium', 'strong'
    
    # é«˜çº§å¢å¼º
    USE_CUTMIX = True
    CUTMIX_ALPHA = 1.0
    USE_MIXUP = True
    MIXUP_ALPHA = 0.2
    
    # å¼ºæ•°æ®å¢å¼ºé…ç½®
    STRONG_AUGMENTATION = {
        'randaugment_n': 2,
        'randaugment_m': 10,
        'cutout_n_holes': 1,
        'cutout_length': 16,
        'auto_augment_policy': 'imagenet',
    }
    
    # åŸºç¡€æ•°æ®å¢å¼ºï¼ˆä¿ç•™åŸé…ç½®ï¼‰
    PRETRAIN_AUGMENTATION = {
        'resize': (256, 256),
        'crop_scale': (0.2, 1.0),
        'crop_ratio': (0.75, 1.33),
        'horizontal_flip_p': 0.5,
        'vertical_flip_p': 0.3,
        'rotation_degrees': 30,
        'color_jitter': {
            'brightness': 0.4,
            'contrast': 0.4,
            'saturation': 0.4,
            'hue': 0.2
        },
        'grayscale_p': 0.1,
        'gaussian_blur': {
            'kernel_size': 3,
            'sigma': (0.1, 2.0)
        }
    }
    
    FINETUNE_AUGMENTATION = {
        'resize': (256, 256),
        'crop_size': 224,
        'horizontal_flip_p': 0.5,
        'rotation_degrees': 15,
        'color_jitter': {
            'brightness': 0.3,
            'contrast': 0.3,
            'saturation': 0.3,
            'hue': 0.1
        }
    }
    
    # å›¾åƒå½’ä¸€åŒ–å‚æ•°
    NORMALIZE_MEAN = [0.485, 0.456, 0.406]
    NORMALIZE_STD = [0.229, 0.224, 0.225]
    
    # ============================== é›†æˆå­¦ä¹ é…ç½® ==============================
    USE_ENSEMBLE = False  # æ˜¯å¦ä½¿ç”¨æ¨¡å‹é›†æˆ
    ENSEMBLE_MODELS = [
        'vit_base_patch16_224.dino',
        'convnext_base.fb_in22k_ft_in1k',
        'swin_base_patch4_window7_224'
    ]
    
    # ============================== çŸ¥è¯†è’¸é¦é…ç½® ==============================
    USE_KNOWLEDGE_DISTILLATION = False  # æ˜¯å¦ä½¿ç”¨çŸ¥è¯†è’¸é¦
    TEACHER_MODEL = 'vit_large_patch16_224'  # æ•™å¸ˆæ¨¡å‹
    DISTILLATION_TEMPERATURE = 4.0
    DISTILLATION_ALPHA = 0.7  # è’¸é¦æŸå¤±æƒé‡
    
    @classmethod
    def get_config_dict(cls):
        """è·å–æ‰€æœ‰é…ç½®å‚æ•°çš„å­—å…¸å½¢å¼"""
        return {
            key: value for key, value in cls.__dict__.items()
            if not key.startswith('_') and not callable(value)
        }
    
    @classmethod
    def print_config(cls):
        """æ‰“å°æ‰€æœ‰é…ç½®å‚æ•°"""
        print("="*60)
        print("é…ç½®å‚æ•°:")
        print("="*60)
        print(f"ğŸ”§ æ¨¡å‹ç±»å‹: {cls.MODEL_TYPE}")
        print(f"ğŸ”§ é¢„è®­ç»ƒæ¨¡å‹: {cls.PRETRAINED_MODEL_NAME if cls.USE_PRETRAINED_MODEL else 'æ— '}")
        print(f"ğŸ”§ ä½¿ç”¨æ··åˆç²¾åº¦: {cls.USE_AMP}")
        print(f"ğŸ”§ ä½¿ç”¨SAMä¼˜åŒ–å™¨: {cls.USE_SAM}")
        print(f"ğŸ”§ æ•°æ®å¢å¼ºçº§åˆ«: {cls.AUGMENTATION_LEVEL}")
        print("="*60)
        
        config_dict = cls.get_config_dict()
        for key, value in sorted(config_dict.items()):
            if not isinstance(value, dict):  # è·³è¿‡å­—å…¸ç±»å‹çš„é…ç½®
                print(f"{key}: {value}")
        print("="*60)
    
    @classmethod
    def create_directories(cls):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        os.makedirs(cls.CHECKPOINT_DIR, exist_ok=True)