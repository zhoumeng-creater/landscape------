"""
è¯„ä¼°å‡½æ•°æ¨¡å— - æ¨¡å‹è¯„ä¼°ç›¸å…³å‡½æ•°
åŒ…å«åŸç‰ˆæœ¬å’Œæ–°å¢çš„é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°å‡½æ•°
"""
import torch
import torch.nn.functional as F
import numpy as np
from sklearn.metrics import (
    accuracy_score, f1_score, precision_score, recall_score,
    classification_report, confusion_matrix, roc_auc_score,
    balanced_accuracy_score, cohen_kappa_score
)
from config import Config
from data.transforms import get_tta_transforms
from torch.cuda.amp import autocast


def evaluate_optimized_model(ijepa_model, classifier, test_loader, label_encoder):
    """è¯„ä¼°ä¼˜åŒ–æ¨¡å‹ï¼ˆåŸç‰ˆæœ¬ï¼‰
    
    Args:
        ijepa_model: I-JEPAæ¨¡å‹
        classifier: åˆ†ç±»å™¨
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        label_encoder: æ ‡ç­¾ç¼–ç å™¨
        
    Returns:
        results: è¯„ä¼°ç»“æœå­—å…¸
        predictions: æ‰€æœ‰é¢„æµ‹
        targets: æ‰€æœ‰çœŸå®æ ‡ç­¾
    """
    device = Config.DEVICE
    ijepa_model.eval()
    classifier.eval()
    
    all_predictions = []
    all_targets = []
    all_probabilities = []
    
    print("ğŸ” æ­£åœ¨è¯„ä¼°ä¼˜åŒ–æ¨¡å‹...")
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            
            # æå–ç‰¹å¾
            features = ijepa_model.encode(data)
            
            # åˆ†ç±»é¢„æµ‹
            output = classifier(features)
            probabilities = F.softmax(output, dim=1)
            _, predicted = torch.max(output, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    all_probabilities = np.array(all_probabilities)
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    results = calculate_metrics(all_targets, all_predictions, all_probabilities)
    
    # æ‰“å°ç»“æœ
    print_evaluation_results(results, label_encoder)
    
    return results, all_predictions, all_targets


def evaluate_pretrained_model(model, test_loader, label_encoder, use_tta=False):
    """è¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæ–°å¢ï¼‰
    
    Args:
        model: é¢„è®­ç»ƒæ¨¡å‹
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        label_encoder: æ ‡ç­¾ç¼–ç å™¨
        use_tta: æ˜¯å¦ä½¿ç”¨æµ‹è¯•æ—¶å¢å¼º
        
    Returns:
        results: è¯„ä¼°ç»“æœå­—å…¸
        predictions: æ‰€æœ‰é¢„æµ‹
        targets: æ‰€æœ‰çœŸå®æ ‡ç­¾
    """
    device = Config.DEVICE
    model.eval()
    
    all_predictions = []
    all_targets = []
    all_probabilities = []
    
    print("ğŸ” æ­£åœ¨è¯„ä¼°é¢„è®­ç»ƒæ¨¡å‹...")
    if use_tta:
        print("  ä½¿ç”¨æµ‹è¯•æ—¶å¢å¼º(TTA)...")
    
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(test_loader):
            data, target = data.to(device), target.to(device)
            
            if use_tta:
                # æµ‹è¯•æ—¶å¢å¼º
                probabilities = perform_tta(model, data)
            else:
                # æ ‡å‡†é¢„æµ‹
                with autocast(enabled=Config.USE_AMP):
                    output = model(data)
                    if isinstance(output, tuple):
                        logits, _ = output
                    else:
                        logits = output
                    probabilities = F.softmax(logits, dim=1)
            
            _, predicted = torch.max(probabilities, 1)
            
            all_predictions.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())
            
            # æ‰“å°è¿›åº¦
            if batch_idx % 10 == 0:
                print(f"  å¤„ç†æ‰¹æ¬¡ {batch_idx}/{len(test_loader)}")
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    all_predictions = np.array(all_predictions)
    all_targets = np.array(all_targets)
    all_probabilities = np.array(all_probabilities)
    
    # è®¡ç®—å„ç§æŒ‡æ ‡
    results = calculate_metrics(all_targets, all_predictions, all_probabilities)
    
    # æ‰“å°ç»“æœ
    print_evaluation_results(results, label_encoder)
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    generate_detailed_report(all_targets, all_predictions, all_probabilities, label_encoder)
    
    return results, all_predictions, all_targets


def perform_tta(model, data):
    """æ‰§è¡Œæµ‹è¯•æ—¶å¢å¼º
    
    Args:
        model: æ¨¡å‹
        data: è¾“å…¥æ•°æ®ï¼ˆå·²ç»æ˜¯tensorï¼‰
        
    Returns:
        averaged_probs: å¹³å‡æ¦‚ç‡
    """
    # è·å–TTAå˜æ¢
    tta_transforms = get_tta_transforms()
    
    # å­˜å‚¨æ‰€æœ‰é¢„æµ‹
    all_probs = []
    
    # åŸå§‹é¢„æµ‹
    with autocast(enabled=Config.USE_AMP):
        output = model(data)
        if isinstance(output, tuple):
            logits, _ = output
        else:
            logits = output
        probs = F.softmax(logits, dim=1)
        all_probs.append(probs)
    
    # TTAé¢„æµ‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå› ä¸ºè¾“å…¥å·²ç»æ˜¯tensorï¼‰
    # æ°´å¹³ç¿»è½¬
    flipped_data = torch.flip(data, dims=[3])  # æ°´å¹³ç¿»è½¬
    with autocast(enabled=Config.USE_AMP):
        output = model(flipped_data)
        if isinstance(output, tuple):
            logits, _ = output
        else:
            logits = output
        probs = F.softmax(logits, dim=1)
        all_probs.append(probs)
    
    # å°è§’åº¦æ—‹è½¬ï¼ˆä½¿ç”¨torchçš„æ—‹è½¬ï¼‰
    for angle in [-5, 5]:
        angle_rad = angle * np.pi / 180
        theta = torch.tensor([
            [np.cos(angle_rad), -np.sin(angle_rad), 0],
            [np.sin(angle_rad), np.cos(angle_rad), 0]
        ], dtype=torch.float32).unsqueeze(0).repeat(data.size(0), 1, 1).to(data.device)
        
        grid = F.affine_grid(theta, data.size(), align_corners=False)
        rotated_data = F.grid_sample(data, grid, align_corners=False)
        
        with autocast(enabled=Config.USE_AMP):
            output = model(rotated_data)
            if isinstance(output, tuple):
                logits, _ = output
            else:
                logits = output
            probs = F.softmax(logits, dim=1)
            all_probs.append(probs)
    
    # å¹³å‡æ‰€æœ‰é¢„æµ‹
    averaged_probs = torch.stack(all_probs).mean(dim=0)
    
    return averaged_probs


def calculate_metrics(y_true, y_pred, y_prob=None):
    """è®¡ç®—å„ç§è¯„ä¼°æŒ‡æ ‡ï¼ˆä¿ç•™åŸç‰ˆæœ¬ï¼‰"""
    metrics = {}
    
    # åŸºç¡€æŒ‡æ ‡
    metrics['accuracy'] = accuracy_score(y_true, y_pred)
    metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)
    metrics['cohen_kappa'] = cohen_kappa_score(y_true, y_pred)
    
    # F1åˆ†æ•°ï¼ˆå¤šç§å¹³å‡æ–¹å¼ï¼‰
    metrics['f1_macro'] = f1_score(y_true, y_pred, average='macro')
    metrics['f1_micro'] = f1_score(y_true, y_pred, average='micro')
    metrics['f1_weighted'] = f1_score(y_true, y_pred, average='weighted')
    
    # ç²¾ç¡®ç‡å’Œå¬å›ç‡
    metrics['precision_macro'] = precision_score(y_true, y_pred, average='macro')
    metrics['precision_weighted'] = precision_score(y_true, y_pred, average='weighted')
    metrics['recall_macro'] = recall_score(y_true, y_pred, average='macro')
    metrics['recall_weighted'] = recall_score(y_true, y_pred, average='weighted')
    
    # å¦‚æœæœ‰æ¦‚ç‡é¢„æµ‹ï¼Œè®¡ç®—AUC
    if y_prob is not None:
        try:
            # å¤šåˆ†ç±»AUC
            num_classes = y_prob.shape[1]
            if num_classes > 2:
                metrics['auc_macro'] = roc_auc_score(y_true, y_prob, 
                                                    multi_class='ovr', average='macro')
                metrics['auc_weighted'] = roc_auc_score(y_true, y_prob, 
                                                       multi_class='ovr', average='weighted')
        except:
            metrics['auc_macro'] = None
            metrics['auc_weighted'] = None
    
    # æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
    metrics['per_class_f1'] = f1_score(y_true, y_pred, average=None)
    metrics['per_class_precision'] = precision_score(y_true, y_pred, average=None)
    metrics['per_class_recall'] = recall_score(y_true, y_pred, average=None)
    
    return metrics


def print_evaluation_results(results, label_encoder):
    """æ‰“å°è¯„ä¼°ç»“æœï¼ˆå¢å¼ºç‰ˆæœ¬ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ“Š æ¨¡å‹æµ‹è¯•ç»“æœ:")
    print("="*60)
    
    # æ‰“å°æ€»ä½“æŒ‡æ ‡
    print(f"\nğŸ¯ æ€»ä½“æ€§èƒ½æŒ‡æ ‡:")
    print(f"  å‡†ç¡®ç‡ (Accuracy): {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)")
    print(f"  å¹³è¡¡å‡†ç¡®ç‡ (Balanced Accuracy): {results['balanced_accuracy']:.4f}")
    print(f"  Cohen's Kappa: {results['cohen_kappa']:.4f}")
    
    print(f"\nğŸ“ˆ F1åˆ†æ•°:")
    print(f"  å®å¹³å‡ (Macro): {results['f1_macro']:.4f}")
    print(f"  å¾®å¹³å‡ (Micro): {results['f1_micro']:.4f}")
    print(f"  åŠ æƒå¹³å‡ (Weighted): {results['f1_weighted']:.4f}")
    
    print(f"\nğŸª ç²¾ç¡®ç‡å’Œå¬å›ç‡:")
    print(f"  ç²¾ç¡®ç‡ - å®å¹³å‡: {results['precision_macro']:.4f}")
    print(f"  ç²¾ç¡®ç‡ - åŠ æƒå¹³å‡: {results['precision_weighted']:.4f}")
    print(f"  å¬å›ç‡ - å®å¹³å‡: {results['recall_macro']:.4f}")
    print(f"  å¬å›ç‡ - åŠ æƒå¹³å‡: {results['recall_weighted']:.4f}")
    
    if results.get('auc_macro') is not None:
        print(f"\nğŸ“Š AUCåˆ†æ•°:")
        print(f"  å®å¹³å‡: {results['auc_macro']:.4f}")
        print(f"  åŠ æƒå¹³å‡: {results['auc_weighted']:.4f}")
    
    # æ‰“å°æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½
    print(f"\nğŸ·ï¸ æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½:")
    class_names = label_encoder.classes_
    
    # æ‰¾å‡ºè¡¨ç°æœ€å¥½å’Œæœ€å·®çš„ç±»åˆ«
    f1_scores = results['per_class_f1']
    best_class_idx = np.argmax(f1_scores)
    worst_class_idx = np.argmin(f1_scores)
    
    for i, class_name in enumerate(class_names):
        if i < len(results['per_class_f1']):
            marker = ""
            if i == best_class_idx:
                marker = " â­ (æœ€ä½³)"
            elif i == worst_class_idx:
                marker = " âš ï¸  (æœ€å·®)"
            
            print(f"  {class_name}{marker}:")
            print(f"    F1: {results['per_class_f1'][i]:.3f} | "
                  f"ç²¾ç¡®ç‡: {results['per_class_precision'][i]:.3f} | "
                  f"å¬å›ç‡: {results['per_class_recall'][i]:.3f}")
    
    print("="*60)


def generate_detailed_report(y_true, y_pred, y_prob, label_encoder):
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Šï¼ˆæ–°å¢ï¼‰"""
    print("\n" + "="*60)
    print("ğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print("="*60)
    
    # ç”Ÿæˆåˆ†ç±»æŠ¥å‘Š
    report = classification_report(
        y_true, y_pred, 
        target_names=label_encoder.classes_,
        digits=3
    )
    print(report)
    
    # è®¡ç®—å¹¶æ˜¾ç¤ºç½®ä¿¡åº¦ç»Ÿè®¡
    if y_prob is not None:
        max_probs = np.max(y_prob, axis=1)
        correct_mask = y_pred == y_true
        
        print("\nğŸ“Š é¢„æµ‹ç½®ä¿¡åº¦åˆ†æ:")
        print(f"  å¹³å‡ç½®ä¿¡åº¦: {np.mean(max_probs):.3f}")
        print(f"  æ­£ç¡®é¢„æµ‹çš„å¹³å‡ç½®ä¿¡åº¦: {np.mean(max_probs[correct_mask]):.3f}")
        print(f"  é”™è¯¯é¢„æµ‹çš„å¹³å‡ç½®ä¿¡åº¦: {np.mean(max_probs[~correct_mask]):.3f}")
        
        # é«˜ç½®ä¿¡åº¦ä½†é”™è¯¯çš„é¢„æµ‹
        high_conf_wrong = np.sum((max_probs > 0.9) & (~correct_mask))
        low_conf_correct = np.sum((max_probs < 0.5) & correct_mask)
        
        print(f"\nâš ï¸  æ½œåœ¨é—®é¢˜:")
        print(f"  é«˜ç½®ä¿¡åº¦(>0.9)ä½†é”™è¯¯çš„é¢„æµ‹: {high_conf_wrong} ä¸ª")
        print(f"  ä½ç½®ä¿¡åº¦(<0.5)ä½†æ­£ç¡®çš„é¢„æµ‹: {low_conf_correct} ä¸ª")
    
    print("="*60)