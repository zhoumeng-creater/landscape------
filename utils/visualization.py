"""
å¯è§†åŒ–å·¥å…·æ¨¡å— - ç”¨äºç»˜åˆ¶è®­ç»ƒæ›²çº¿ã€æ··æ·†çŸ©é˜µç­‰
"""
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import confusion_matrix
import torch


def plot_enhanced_learning_curves(history, save_path=None):
    """ç»˜åˆ¶å¢å¼ºçš„å­¦ä¹ æ›²çº¿
    
    Args:
        history: è®­ç»ƒå†å²å­—å…¸
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # æŸå¤±æ›²çº¿
    axes[0, 0].plot(history['train_loss'], label='è®­ç»ƒæŸå¤±', color='blue', linewidth=2)
    axes[0, 0].plot(history['val_loss'], label='éªŒè¯æŸå¤±', color='red', linewidth=2)
    axes[0, 0].set_title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('æŸå¤±')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # å‡†ç¡®ç‡æ›²çº¿
    axes[0, 1].plot(history['train_acc'], label='è®­ç»ƒå‡†ç¡®ç‡', color='blue', linewidth=2)
    axes[0, 1].plot(history['val_acc'], label='éªŒè¯å‡†ç¡®ç‡', color='red', linewidth=2)
    axes[0, 1].set_title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('å‡†ç¡®ç‡ (%)')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # æŸå¤±å¹³æ»‘è¶‹åŠ¿
    if len(history['train_loss']) > 5:
        window_size = 5
        train_smooth = np.convolve(history['train_loss'], np.ones(window_size)/window_size, mode='valid')
        val_smooth = np.convolve(history['val_loss'], np.ones(window_size)/window_size, mode='valid')
        
        axes[1, 0].plot(range(window_size-1, len(train_smooth) + window_size-1), train_smooth, 
                       label='è®­ç»ƒæŸå¤±(å¹³æ»‘)', color='blue', linewidth=2)
        axes[1, 0].plot(range(window_size-1, len(val_smooth) + window_size-1), val_smooth, 
                       label='éªŒè¯æŸå¤±(å¹³æ»‘)', color='red', linewidth=2)
        axes[1, 0].set_title('æŸå¤±å¹³æ»‘è¶‹åŠ¿', fontsize=14, fontweight='bold')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('æŸå¤±')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
    
    # æ€§èƒ½æ€»ç»“
    final_train_acc = history['train_acc'][-1]
    final_val_acc = history['val_acc'][-1]
    best_val_acc = max(history['val_acc'])
    best_epoch = history['val_acc'].index(best_val_acc) + 1
    
    summary_text = f"""ğŸ† æ€§èƒ½æ€»ç»“
    
æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.2f}%
æœ€ä½³è½®æ¬¡: {best_epoch}
æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {final_train_acc:.2f}%
æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {final_val_acc:.2f}%
å‡†ç¡®ç‡å·®è·: {final_train_acc - final_val_acc:.2f}%

æ¨¡å‹çŠ¶æ€: """
    
    acc_gap = final_train_acc - final_val_acc
    if acc_gap > 15:
        status = "âš ï¸  å¯èƒ½è¿‡æ‹Ÿåˆ"
        color = 'red'
    elif final_val_acc < 60:
        status = "âš ï¸  å¯èƒ½æ¬ æ‹Ÿåˆ"  
        color = 'orange'
    else:
        status = "âœ… æ€§èƒ½è‰¯å¥½"
        color = 'green'
    
    summary_text += status
    
    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=12, 
                   transform=axes[1, 1].transAxes, verticalalignment='center')
    axes[1, 1].text(0.1, 0.15, status, fontsize=14, fontweight='bold',
                   transform=axes[1, 1].transAxes, color=color)
    axes[1, 1].axis('off')
    
    plt.suptitle('ä¼˜åŒ–ç‰ˆI-JEPAå›­æ—åˆ†ç±»ç³»ç»Ÿ - å­¦ä¹ æ›²çº¿åˆ†æ', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


def plot_pretrain_curves(history, save_path=None):
    """ç»˜åˆ¶é¢„è®­ç»ƒæ›²çº¿
    
    Args:
        history: é¢„è®­ç»ƒå†å²
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # æŸå¤±æ›²çº¿
    axes[0, 0].plot(history['loss'], 'b-', linewidth=2)
    axes[0, 0].set_title('é¢„è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('æŸå¤±')
    axes[0, 0].grid(True, alpha=0.3)
    
    # ä½™å¼¦ç›¸ä¼¼åº¦æ›²çº¿
    axes[0, 1].plot(history['cosine_similarity'], 'g-', linewidth=2)
    axes[0, 1].set_title('ä½™å¼¦ç›¸ä¼¼åº¦è¶‹åŠ¿', fontsize=14, fontweight='bold')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('ä½™å¼¦ç›¸ä¼¼åº¦')
    axes[0, 1].grid(True, alpha=0.3)
    
    # ç‰¹å¾å¤šæ ·æ€§æ›²çº¿
    axes[1, 0].plot(history['feature_diversity'], 'r-', linewidth=2)
    axes[1, 0].set_title('ç‰¹å¾å¤šæ ·æ€§', fontsize=14, fontweight='bold')
    axes[1, 0].set_xlabel('Epoch')
    axes[1, 0].set_ylabel('ç‰¹å¾æ ‡å‡†å·®')
    axes[1, 0].grid(True, alpha=0.3)
    
    # å­¦ä¹ ç‡æ›²çº¿
    axes[1, 1].plot(history['learning_rate'], 'm-', linewidth=2)
    axes[1, 1].set_title('å­¦ä¹ ç‡å˜åŒ–', fontsize=14, fontweight='bold')
    axes[1, 1].set_xlabel('Epoch')
    axes[1, 1].set_ylabel('å­¦ä¹ ç‡')
    axes[1, 1].set_yscale('log')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.suptitle('I-JEPAé¢„è®­ç»ƒç›‘æ§', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None):
    """ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    
    Args:
        y_true: çœŸå®æ ‡ç­¾
        y_pred: é¢„æµ‹æ ‡ç­¾
        class_names: ç±»åˆ«åç§°
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_pred)
    
    # åˆ›å»ºå›¾å½¢
    plt.figure(figsize=(12, 10))
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=class_names, yticklabels=class_names,
                cbar_kws={'label': 'æ ·æœ¬æ•°'})
    
    plt.title('ä¼˜åŒ–ç‰ˆI-JEPA - æ··æ·†çŸ©é˜µ', fontsize=16, fontweight='bold')
    plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
    plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    
    # æ·»åŠ å‡†ç¡®ç‡ä¿¡æ¯
    accuracy = np.trace(cm) / np.sum(cm)
    plt.text(0.5, -0.15, f'æ€»ä½“å‡†ç¡®ç‡: {accuracy:.2%}', 
             transform=plt.gca().transAxes, ha='center', fontsize=14)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


def plot_class_distribution(labels, class_names, save_path=None):
    """ç»˜åˆ¶ç±»åˆ«åˆ†å¸ƒå›¾
    
    Args:
        labels: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–æ•´æ•°ï¼‰
        class_names: ç±»åˆ«åç§°åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    unique, counts = np.unique(labels, return_counts=True)
    
    # åˆ›å»ºæ¡å½¢å›¾
    plt.figure(figsize=(15, 8))
    bars = plt.bar(range(len(unique)), counts)
    
    # è®¾ç½®é¢œè‰²
    colors = plt.cm.viridis(counts / max(counts))
    for bar, color in zip(bars, colors):
        bar.set_color(color)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, count in enumerate(counts):
        plt.text(i, count + max(counts)*0.01, str(count), 
                ha='center', va='bottom', fontsize=10)
    
    plt.title('å„å›­æ—ç±»åˆ«å›¾åƒæ•°é‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
    plt.xlabel('å›­æ—ç±»åˆ«', fontsize=12)
    plt.ylabel('å›¾åƒæ•°é‡', fontsize=12)
    
    # å¤„ç†xè½´æ ‡ç­¾
    # å¦‚æœlabelsæ˜¯å­—ç¬¦ä¸²ï¼Œuniqueä¹Ÿæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
    # å¦‚æœlabelsæ˜¯æ•´æ•°ï¼ˆç¼–ç åçš„ï¼‰ï¼Œéœ€è¦ç”¨class_namesè§£ç 
    if isinstance(unique[0], (int, np.integer)):
        # labelsæ˜¯ç¼–ç åçš„æ•´æ•°
        x_labels = [class_names[i] for i in unique]
    else:
        # labelsæ˜¯åŸå§‹å­—ç¬¦ä¸²
        x_labels = unique
    
    plt.xticks(range(len(unique)), x_labels, rotation=45, ha='right')
    
    # æ·»åŠ å¹³å‡çº¿
    mean_count = np.mean(counts)
    plt.axhline(y=mean_count, color='r', linestyle='--', alpha=0.7, 
                label=f'å¹³å‡æ•°é‡: {mean_count:.0f}')
    plt.legend()
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()


def visualize_attention_weights(attention_weights, save_path=None):
    """å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡
    
    Args:
        attention_weights: æ³¨æ„åŠ›æƒé‡çŸ©é˜µ
        save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    if isinstance(attention_weights, torch.Tensor):
        attention_weights = attention_weights.detach().cpu().numpy()
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(attention_weights, cmap='hot', cbar=True)
    plt.title('æ³¨æ„åŠ›æƒé‡å¯è§†åŒ–', fontsize=14, fontweight='bold')
    plt.xlabel('Keyä½ç½®')
    plt.ylabel('Queryä½ç½®')
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()